name: Text to Video Generation (CPU)

on:
  workflow_dispatch:
    inputs:
      prompt:
        description: 'Text prompt for video generation'
        required: true
        default: 'A beautiful sunset over the mountains'
      style:
        description: 'Animation style (pixar, anime, watercolor, cyberpunk, claymation)'
        required: false
        default: 'pixar'
      num_frames:
        description: 'Number of frames to generate (max 16 for CPU)'
        required: false
        default: '8'
      fps:
        description: 'Frames per second for the output video'
        required: false
        default: '4'
      seed:
        description: 'Random seed for reproducibility'
        required: false
        default: '42'

jobs:
  generate-video:
    runs-on: ubuntu-latest
    
    # Use larger runner for more memory
    strategy:
      matrix:
        python-version: ['3.10']
    
    steps:
    - name: Checkout repository
      uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v4
      with:
        python-version: ${{ matrix.python-version }}
    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y ffmpeg python3-pip
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.10'
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements_video.txt
    
    - name: Generate video
      timeout-minutes: 30
      env:
        STABILITY_API_KEY: ${{ secrets.STABILITY_API_KEY }}
        PYTHONUNBUFFERED: 1
        INPUT_PROMPT: ${{ github.event.inputs.prompt }}
        INPUT_STYLE: ${{ github.event.inputs.style }}
        INPUT_FRAMES: ${{ github.event.inputs.num_frames }}
        INPUT_FPS: ${{ github.event.inputs.fps }}
        INPUT_SEED: ${{ github.event.inputs.seed }}
      run: |
        # Create output directory
        mkdir -p output_videos
        
        # Set default values if inputs are not provided
        PROMPT="${INPUT_PROMPT:-'A beautiful landscape'}"
        STYLE="${INPUT_STYLE:-'pixar'}"
        FRAMES="${INPUT_FRAMES:-8}"
        FPS="${INPUT_FPS:-4}"
        SEED="${INPUT_SEED:-42}"
        
        echo "=== Starting Video Generation ==="
        echo "Prompt: $PROMPT"
        echo "Style: $STYLE"
        echo "Frames: $FRAMES"
        echo "FPS: $FPS"
        echo "Seed: $SEED"
        
        # Run the script with the input parameters
        python text_to_video.py \
          --prompt "$PROMPT" \
          --style "$STYLE" \
          --frames "$FRAMES" \
          --fps "$FPS" \
          --seed "$SEED" \
          --output "generated"
        
        # List the generated files for debugging
        echo "\n=== Generated Files ==="
        ls -la output_videos/
    
    - name: Upload GIF artifact
      uses: actions/upload-artifact@v4
      with:
        name: generated-animation
        path: output_videos/*.gif
        if-no-files-found: error
        retention-days: 1
    
    - name: Display GIF info
      if: success()
      run: |
        echo "=== GIF Generation Completed ==="
        echo "Check the 'Artifacts' section above to download the generated GIF."
        echo "File size: $(ls -lh output_videos/*.gif | awk '{print $5}')B"
        ls -la output_videos/ 2>/dev/null || echo "No output directory found"
        
        # Check for any errors in the logs
        echo -e "\n=== Log Summary ==="
        grep -i -E 'error|warning|exception|traceback' $GITHUB_STEP_SUMMARY 2>/dev/null || echo "No errors found in logs"
        echo -e "\n=== Disk Usage ==="
        df -h
        echo -e "\n=== Memory Usage ==="
        free -h
